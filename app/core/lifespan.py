"""
åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†

ç®¡ç†åº”ç”¨å¯åŠ¨å’Œå…³é—­æ—¶çš„èµ„æºåˆå§‹åŒ–å’Œæ¸…ç†
"""

from contextlib import asynccontextmanager
from typing import Any

from fastapi import FastAPI
from loguru import logger

from app.core.checkpointer import close_checkpointer, get_checkpointer, init_checkpointer
from app.core.config import settings
from app.core.database import close_db, init_db
from app.core.graph import create_graph

# å…¨å±€å˜é‡ç”¨äºå­˜å‚¨é»˜è®¤ç¼–è¯‘åçš„å›¾
compiled_graph: Any | None = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨

    å¯åŠ¨æ—¶:
    - åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    - åˆ›å»ºæ•°æ®åº“è¡¨ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    - åˆå§‹åŒ– LangGraph checkpointer
    - ç¼–è¯‘ LangGraph å›¾

    å…³é—­æ—¶:
    - å…³é—­æ•°æ®åº“è¿æ¥
    - å…³é—­ checkpointer è¿æ¥
    - æ¸…ç†èµ„æº
    """
    global compiled_graph

    # å¯åŠ¨æ—¶
    logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")

    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        await init_db()
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")

        # åˆå§‹åŒ– LangGraph checkpointerï¼ˆä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰
        checkpointer = await init_checkpointer(settings.CHECKPOINT_DB_PATH)

        # åˆ›å»º Agent å›¾ï¼ˆä¼ å…¥ checkpointer ä»¥æ”¯æŒçŠ¶æ€æŒä¹…åŒ–ï¼‰
        compiled_graph = await create_graph(checkpointer=checkpointer)
        logger.info("âœ… LangGraph å›¾ç¼–è¯‘æˆåŠŸ")

    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

    logger.info("âœ… åº”ç”¨å¯åŠ¨å®Œæˆ")

    yield

    # å…³é—­æ—¶
    logger.info("ğŸ›‘ åº”ç”¨å…³é—­ä¸­...")

    try:
        await close_db()
        logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")

        await close_checkpointer()
        logger.info("âœ… Checkpointer è¿æ¥å·²å…³é—­")

    except Exception as e:
        logger.error(f"âŒ å…³é—­å¤±è´¥: {e}")

    logger.info("âœ… åº”ç”¨å·²å…³é—­")


def get_compiled_graph() -> Any:
    """
    è·å–é»˜è®¤ç¼–è¯‘åçš„ LangGraph å›¾ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å›¾å¯¹è±¡

    Raises:
        RuntimeError: å¦‚æœå›¾æœªåˆå§‹åŒ–
    """
    if compiled_graph is None:
        raise RuntimeError("Graph not initialized. Application may not have started properly.")
    return compiled_graph


async def get_cached_graph(
    llm_model: str | None = None,
    api_key: str | None = None,
    base_url: str | None = None,
    max_tokens: int = 4096,
) -> Any:
    """
    è·å–ç¼“å­˜çš„ LangGraph å›¾ï¼ˆæ ¹æ®ç”¨æˆ·é…ç½®ï¼‰

    æ³¨æ„: ç”±äºæ”¹ä¸ºå¼‚æ­¥å‡½æ•°ï¼Œç¼“å­˜åŠŸèƒ½å·²ç§»é™¤ã€‚å¦‚éœ€ç¼“å­˜ï¼Œå»ºè®®åœ¨åº”ç”¨å±‚å®ç°ã€‚

    Args:
        llm_model: LLM æ¨¡å‹åç§°
        api_key: API å¯†é’¥
        base_url: API åŸºç¡€ URL
        max_tokens: æœ€å¤§ token æ•°

    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å›¾å¯¹è±¡

    Note:
        - æ‰€æœ‰å›¾å®ä¾‹å…±äº«åŒä¸€ä¸ª checkpointerï¼ˆçŠ¶æ€æŒä¹…åŒ–ï¼‰
    """
    checkpointer = get_checkpointer()
    graph = await create_graph(
        checkpointer=checkpointer,
        llm_model=llm_model,
        api_key=api_key,
        base_url=base_url,
        max_tokens=max_tokens,
    )
    logger.debug(f"Created new graph instance with config: model={llm_model}, max_tokens={max_tokens}")
    return graph
